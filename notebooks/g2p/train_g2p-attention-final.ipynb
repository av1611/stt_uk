{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gzip\n",
    "import time\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../../data/phone_data.json.gz'\n",
    "RANDOM_SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED'] = str(RANDOM_SEED)\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'  # tf 2.0+\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gzip2json(path):\n",
    "    with gzip.GzipFile(path, 'r') as fin:\n",
    "        data = json.loads(fin.read().decode('utf-8'))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gzip2json(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* chr(769) we are replacing stress near letters\n",
    "\n",
    "TODO: think about removing dash '-' as it has no phoneme at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words, letters, phones = [], [], []\n",
    "# ignored = 0\n",
    "\n",
    "# for item in tqdm(data):\n",
    "#     word = item['word'].lower()\n",
    "#     ltrs = [letter for letter in word]\n",
    "#     phns = [phone for phone in item['phones']]\n",
    "# #     phns = [letter.replace(chr(769), '') for letter in item['phones']]\n",
    "    \n",
    "#     if set(['#', \"{и^е}'\", \"{о^у}'\", \"о'\", \"ґ'\"]).intersection(phns):\n",
    "#         ignored += 1\n",
    "#         continue\n",
    "       \n",
    "#     words.append(word)\n",
    "#     letters.append(ltrs)\n",
    "#     phones.append(phns)\n",
    "\n",
    "# data_preprocessed = list(zip(words, letters, phones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160385/160385 [00:01<00:00, 144074.69it/s]\n"
     ]
    }
   ],
   "source": [
    "words, letters, phones = [], [], []\n",
    "ignored = 0\n",
    "\n",
    "for item in tqdm(data):\n",
    "    word = item['word'].lower()\n",
    "    \n",
    "    phns = []\n",
    "    for phone in item['phones']:\n",
    "        if chr(769) in phone and len(phone) == 2:\n",
    "            phns += phone.replace(chr(769), ' <stress>').split()\n",
    "        else:\n",
    "            phns += [phone]\n",
    "    \n",
    "    ltrs = [letter for letter in word]\n",
    "        \n",
    "    if set(['#', \"{и^е}'\", \"{о^у}'\", \"о'\", \"ґ'\"]).intersection(phns):\n",
    "        ignored += 1\n",
    "        continue\n",
    "    words.append(word)\n",
    "    letters.append(ltrs)\n",
    "    phones.append(phns)\n",
    "\n",
    "data_preprocessed = list(zip(words, letters, phones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessed = list(zip(words, letters, phones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word:  перепрошений\n",
      "letters:  ['п', 'е', 'р', 'е', 'п', 'р', 'о', 'ш', 'е', 'н', 'и', 'й']\n",
      "phonemes:  ['п', '{е^и}', 'р', '{е^и}', 'п', 'р', 'о', '<stress>', 'ш', '{е^и}', 'н', 'и', 'й']\n"
     ]
    }
   ],
   "source": [
    "sample = random.choice(data_preprocessed)\n",
    "print(f'word: ', sample[0])\n",
    "print(f'letters: ', sample[1])\n",
    "print(f'phonemes: ', sample[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(array):\n",
    "    for item in array:\n",
    "        if isinstance(item, list):\n",
    "            yield from flatten(item)\n",
    "        else:\n",
    "            yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceTokenizer:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.word2index = {}\n",
    "        self.index2word = {}\n",
    "        self.oov_token ='<UNK>'\n",
    "        self.oov_token_index = 0\n",
    "        \n",
    "    def fit(self, sequence):\n",
    "        self.index2word = dict(enumerate([self.oov_token] + sorted(set(flatten(sequence))), 1))\n",
    "        self.word2index = {v:k for k,v in self.index2word.items()}\n",
    "        self.oov_token_index = self.word2index.get(self.oov_token)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        res = []\n",
    "        for line in X:\n",
    "            res.append([self.word2index.get(item, self.oov_token_index) for item in line])\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(x, max_len=None):\n",
    "    return tf.keras.preprocessing.sequence.pad_sequences(x, \n",
    "                                                         padding='post',\n",
    "                                                         maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sep_tokens(x):\n",
    "    return ['<start>'] + x + ['<end>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = list(map(add_sep_tokens, letters))\n",
    "target_sequences = list(map(add_sep_tokens, phones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 36\n"
     ]
    }
   ],
   "source": [
    "max_len_encoder = max(map(lambda x: len(x), input_sequences))\n",
    "max_len_decoder = max(map(lambda x: len(x), target_sequences))\n",
    "print(max_len_encoder, max_len_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_encode = SequenceTokenizer().fit(input_sequences)\n",
    "tokenizer_decode = SequenceTokenizer().fit(target_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_token = tokenizer_encode.transform(input_sequences)\n",
    "y_token = tokenizer_decode.transform(target_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((160306, 35), (160306, 36))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_padded = pad_sequence(X_token, max_len_encoder)\n",
    "y_padded = pad_sequence(y_token, max_len_decoder)\n",
    "\n",
    "X_padded.shape, y_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_padded, test_size=0.05, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((152290, 35), (152290, 36))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for final validation, with the same seed to make sure that split is the same\n",
    "\n",
    "input_train, input_test, output_train, output_test = train_test_split(\n",
    "    letters, phones, test_size=0.05, random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2seq with Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensor data and params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = X_train.shape[0]\n",
    "BUFFER_SIZE_VAL = X_test.shape[0]\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "steps_per_epoch = BUFFER_SIZE // BATCH_SIZE\n",
    "steps_per_epoch_val = BUFFER_SIZE_VAL // BATCH_SIZE\n",
    "\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_size_encode = len(tokenizer_encode.word2index) + 1\n",
    "vocab_size_decode = len(tokenizer_decode.word2index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_input, max_length_output = X_train.shape[1], y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).shuffle(BUFFER_SIZE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 35]), TensorShape([64, 36]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_output_batch = next(iter(train_dataset))\n",
    "example_input_batch.shape, example_output_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 35, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_size_encode, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 35, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 98)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_size_decode, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define optimizer and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, out, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        dec_input = tf.expand_dims([tokenizer_decode.word2index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        # Teacher forcing - feeding the output as the next input\n",
    "        for t in range(1, out.shape[1]):\n",
    "            # passing enc_output to the decoder\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            loss += loss_function(out[:, t], predictions)\n",
    "\n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(out[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(out.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def val_step(inp, out, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        dec_input = tf.expand_dims([tokenizer_decode.word2index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        # Teacher forcing - feeding the output as the next input\n",
    "        for t in range(1, out.shape[1]):\n",
    "            # passing enc_output to the decoder\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "            loss += loss_function(out[:, t], predictions)\n",
    "\n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(out[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(out.shape[1]))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "loss: 0.1633\tval_loss: 0.0457\texec_time: 409.04 seconds\n",
      "\n",
      "Epoch 2/15\n",
      "loss: 0.0463\tval_loss: 0.0294\texec_time: 368.50 seconds\n",
      "\n",
      "Epoch 3/15\n",
      "loss: 0.0319\tval_loss: 0.0243\texec_time: 370.70 seconds\n",
      "\n",
      "Epoch 4/15\n",
      "loss: 0.0350\tval_loss: 0.0259\texec_time: 368.68 seconds\n",
      "\n",
      "Epoch 5/15\n",
      "loss: 0.0292\tval_loss: 0.0237\texec_time: 367.66 seconds\n",
      "\n",
      "Epoch 6/15\n",
      "loss: 0.0296\tval_loss: 0.0225\texec_time: 368.76 seconds\n",
      "\n",
      "Epoch 7/15\n",
      "loss: 0.0339\tval_loss: 0.0312\texec_time: 371.42 seconds\n",
      "\n",
      "Epoch 8/15\n",
      "loss: 0.0263\tval_loss: 0.0281\texec_time: 368.60 seconds\n",
      "\n",
      "Epoch 9/15\n",
      "loss: 0.0240\tval_loss: 0.0197\texec_time: 368.25 seconds\n",
      "\n",
      "Epoch 10/15\n",
      "loss: 0.0371\tval_loss: 0.0299\texec_time: 369.60 seconds\n",
      "\n",
      "Epoch 11/15\n",
      "loss: 0.0291\tval_loss: 0.0308\texec_time: 367.80 seconds\n",
      "\n",
      "Epoch 12/15\n",
      "loss: 0.0264\tval_loss: 0.0291\texec_time: 367.21 seconds\n",
      "\n",
      "Epoch 13/15\n",
      "loss: 0.0284\tval_loss: 0.0298\texec_time: 367.37 seconds\n",
      "\n",
      "Epoch 14/15\n",
      "loss: 0.0273\tval_loss: 0.0274\texec_time: 367.89 seconds\n",
      "\n",
      "Epoch 15/15\n",
      "loss: 0.0265\tval_loss: 0.0236\texec_time: 367.16 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 15\n",
    "history = {}\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    start_time = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    total_val_loss = 0\n",
    "    \n",
    "    print(f\"Epoch {epoch}/{n_epochs}\")\n",
    "    \n",
    "    for (batch, (inp, targ)) in enumerate(train_dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(test_dataset.take(steps_per_epoch)):\n",
    "        batch_loss = val_step(inp, targ, enc_hidden)\n",
    "        total_val_loss += batch_loss\n",
    "    \n",
    "    print('loss: {loss:.4f}\\tval_loss: {val_loss:.4f}\\texec_time: {exec_time:.2f} seconds\\n'.format(\n",
    "            loss = total_loss / steps_per_epoch, \n",
    "            val_loss = total_val_loss / steps_per_epoch_val,\n",
    "            exec_time = time.time() - start_time))\n",
    "    \n",
    "    history['train'] = history.get('train', []) + [total_loss.numpy() / steps_per_epoch]\n",
    "    history['val'] = history.get('val', []) + [total_val_loss.numpy() / steps_per_epoch_val]\n",
    "            \n",
    "#     saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['train'])\n",
    "plt.plot(history['val'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('val')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f8904be1588>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### validate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(word):\n",
    "    \n",
    "    ltrs = add_sep_tokens([letter for letter in word])\n",
    "    \n",
    "    attention_plot = np.zeros((max_length_output, max_length_input))\n",
    "\n",
    "    inputs = tokenizer_encode.transform([ltrs])\n",
    "    inputs = pad_sequence(inputs, max_len=max_len_encoder)\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([tokenizer_decode.word2index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_output):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "        # storing the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += tokenizer_decode.index2word[predicted_id] + ' '\n",
    "\n",
    "        if tokenizer_decode.index2word[predicted_id] == '<end>':\n",
    "            return result, \" \".join(ltrs), attention_plot\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, \" \".join(ltrs), attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def paraphrase(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted paraphrase: {}'.format(result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'а а х е <stress> н'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate('аахен')[0].replace('<end>', '').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> ч о л о в і к <end>\n",
      "Predicted paraphrase: ч о л {о^у} в' і <stress> к <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "paraphrase('чоловік')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8016it [09:42, 13.77it/s]\n"
     ]
    }
   ],
   "source": [
    "correct_pred = 0\n",
    "incorrect_pred = []\n",
    "total_num = len(input_test)\n",
    "\n",
    "for sample, target in tqdm(zip(input_test, output_test)):\n",
    "    prediction = evaluate(sample)[0].replace('<end>', '').strip()\n",
    "    target = \" \".join(target)\n",
    "    if prediction == target:\n",
    "        correct_pred += 1\n",
    "    else:\n",
    "        incorrect_pred.append((sample, target, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct prediction acc: 0.75\n"
     ]
    }
   ],
   "source": [
    "print(f'correct prediction acc: {correct_pred/total_num:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['в',\n",
       "  'а',\n",
       "  'н',\n",
       "  'т',\n",
       "  'а',\n",
       "  'ж',\n",
       "  'о',\n",
       "  'п',\n",
       "  'і',\n",
       "  'д',\n",
       "  'й',\n",
       "  'о',\n",
       "  'м',\n",
       "  'н',\n",
       "  'і',\n",
       "  'с',\n",
       "  'т',\n",
       "  'ь'],\n",
       " \"в а н т а ж о п' і д й о <stress> м н' і с' т'\",\n",
       " \"в а н т а ж {о^у} п' і д й о <stress> м н' і с' т'\")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_pred[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p36tf20",
   "language": "python",
   "name": "p36tf20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
